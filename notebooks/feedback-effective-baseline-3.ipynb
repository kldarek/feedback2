{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02741,
     "end_time": "2021-12-23T23:15:10.253391",
     "exception": false,
     "start_time": "2021-12-23T23:15:10.225981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:13.997631Z",
     "iopub.status.busy": "2022-07-10T22:15:13.997129Z",
     "iopub.status.idle": "2022-07-10T22:15:14.024454Z",
     "shell.execute_reply": "2022-07-10T22:15:14.023369Z",
     "shell.execute_reply.started": "2022-07-10T22:15:13.997519Z"
    },
    "papermill": {
     "duration": 0.043956,
     "end_time": "2021-12-23T23:15:10.325369",
     "exception": false,
     "start_time": "2021-12-23T23:15:10.281413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE = True # set True for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:15.453758Z",
     "iopub.status.busy": "2022-07-10T22:15:15.452969Z",
     "iopub.status.idle": "2022-07-10T22:15:16.397998Z",
     "shell.execute_reply": "2022-07-10T22:15:16.396846Z",
     "shell.execute_reply.started": "2022-07-10T22:15:15.453714Z"
    },
    "papermill": {
     "duration": 13.976422,
     "end_time": "2021-12-23T23:15:47.962217",
     "exception": false,
     "start_time": "2021-12-23T23:15:33.985795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:16.400915Z",
     "iopub.status.busy": "2022-07-10T22:15:16.400517Z",
     "iopub.status.idle": "2022-07-10T22:15:16.408628Z",
     "shell.execute_reply": "2022-07-10T22:15:16.407127Z",
     "shell.execute_reply.started": "2022-07-10T22:15:16.400875Z"
    },
    "papermill": {
     "duration": 2.266066,
     "end_time": "2021-12-23T23:15:50.276089",
     "exception": false,
     "start_time": "2021-12-23T23:15:48.010023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "EXP_NUM = 0\n",
    "task = \"ner\"\n",
    "model_checkpoint = \"allenai/longformer-base-4096\"\n",
    "max_length = 1024\n",
    "model_path = f'{model_checkpoint.split(\"/\")[-1]}-{EXP_NUM}'\n",
    "\n",
    "# TRAINING HYPERPARAMS\n",
    "BS = 4\n",
    "GRAD_ACC = 8\n",
    "LR = 5e-5\n",
    "WD = 0.01\n",
    "WARMUP = 0.1\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030334,
     "end_time": "2021-12-23T23:15:50.341116",
     "exception": false,
     "start_time": "2021-12-23T23:15:50.310782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:17.738449Z",
     "iopub.status.busy": "2022-07-10T22:15:17.737799Z",
     "iopub.status.idle": "2022-07-10T22:15:18.751317Z",
     "shell.execute_reply": "2022-07-10T22:15:18.750349Z",
     "shell.execute_reply.started": "2022-07-10T22:15:17.738407Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('processed.pickle', 'rb') as handle:\n",
    "    pdf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:18.753360Z",
     "iopub.status.busy": "2022-07-10T22:15:18.752999Z",
     "iopub.status.idle": "2022-07-10T22:15:18.808819Z",
     "shell.execute_reply": "2022-07-10T22:15:18.807947Z",
     "shell.execute_reply.started": "2022-07-10T22:15:18.753322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>offset_mapping</th>\n",
       "      <th>token_class_labels</th>\n",
       "      <th>token_scores_labels</th>\n",
       "      <th>token_examples_mapping</th>\n",
       "      <th>examples_scores</th>\n",
       "      <th>examples_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 30086, 6, 939, 437, 12370, 6, 939, 437, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[(0, 0), (0, 2), (2, 3), (4, 5), (5, 7), (8, 1...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 3, 4, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  fold                                          input_ids  \\\n",
       "0  007ACE74B050     0  [0, 30086, 6, 939, 437, 12370, 6, 939, 437, 16...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      offset_mapping  \\\n",
       "0  [(0, 0), (0, 2), (2, 3), (4, 5), (5, 7), (8, 1...   \n",
       "\n",
       "                                  token_class_labels  \\\n",
       "0  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 token_scores_labels  \\\n",
       "0  [-100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                              token_examples_mapping  \\\n",
       "0  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "               examples_scores             examples_classes  \n",
       "0  [1, 1, 1, 1, 1, 0, 1, 1, 1]  [0, 1, 2, 3, 4, 5, 3, 4, 6]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:18.886313Z",
     "iopub.status.busy": "2022-07-10T22:15:18.886040Z",
     "iopub.status.idle": "2022-07-10T22:15:18.893339Z",
     "shell.execute_reply": "2022-07-10T22:15:18.891797Z",
     "shell.execute_reply.started": "2022-07-10T22:15:18.886288Z"
    },
    "papermill": {
     "duration": 2.343119,
     "end_time": "2021-12-23T23:15:56.829799",
     "exception": false,
     "start_time": "2021-12-23T23:15:54.486680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type2id = {'Lead': 0,\n",
    " 'Position': 1,\n",
    " 'Claim': 2,\n",
    " 'Evidence': 3,\n",
    " 'Counterclaim': 4,\n",
    " 'Rebuttal': 5,\n",
    " 'Concluding Statement': 6,\n",
    " 'Other': 7}\n",
    "\n",
    "id2type = {0: 'Lead',\n",
    " 1: 'Position',\n",
    " 2: 'Claim',\n",
    " 3: 'Evidence',\n",
    " 4: 'Counterclaim',\n",
    " 5: 'Rebuttal',\n",
    " 6: 'Concluding Statement',\n",
    " 7: 'Other',\n",
    " -100: 'Mask'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:19.461774Z",
     "iopub.status.busy": "2022-07-10T22:15:19.461143Z",
     "iopub.status.idle": "2022-07-10T22:15:19.466807Z",
     "shell.execute_reply": "2022-07-10T22:15:19.465713Z",
     "shell.execute_reply.started": "2022-07-10T22:15:19.461741Z"
    }
   },
   "outputs": [],
   "source": [
    "i2l = {\n",
    "    0: 'Ineffective',\n",
    "    1: 'Adequate',\n",
    "    2: 'Effective',\n",
    "    -100: 'Mask'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:20.020976Z",
     "iopub.status.busy": "2022-07-10T22:15:20.020137Z",
     "iopub.status.idle": "2022-07-10T22:15:20.025305Z",
     "shell.execute_reply": "2022-07-10T22:15:20.024240Z",
     "shell.execute_reply.started": "2022-07-10T22:15:20.020940Z"
    },
    "papermill": {
     "duration": 1.327426,
     "end_time": "2021-12-23T23:15:58.222639",
     "exception": false,
     "start_time": "2021-12-23T23:15:56.895213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_LABELS = len(i2l) - 1 # not accounting for -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:20.321864Z",
     "iopub.status.busy": "2022-07-10T22:15:20.321400Z",
     "iopub.status.idle": "2022-07-10T22:15:20.326899Z",
     "shell.execute_reply": "2022-07-10T22:15:20.325872Z",
     "shell.execute_reply.started": "2022-07-10T22:15:20.321828Z"
    },
    "papermill": {
     "duration": 1.379706,
     "end_time": "2021-12-23T23:16:48.702898",
     "exception": false,
     "start_time": "2021-12-23T23:16:47.323192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debugging\n",
    "if SAMPLE: pdf = pdf.sample(n=100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:20.729854Z",
     "iopub.status.busy": "2022-07-10T22:15:20.729462Z",
     "iopub.status.idle": "2022-07-10T22:15:20.734860Z",
     "shell.execute_reply": "2022-07-10T22:15:20.733925Z",
     "shell.execute_reply.started": "2022-07-10T22:15:20.729812Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf.columns = ['essay_id', 'fold', 'input_ids', 'attention_mask', 'offset_mapping',\n",
    "       'token_class_labels', 'labels', 'token_examples_mapping',\n",
    "       'examples_scores', 'examples_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:21.078553Z",
     "iopub.status.busy": "2022-07-10T22:15:21.077886Z",
     "iopub.status.idle": "2022-07-10T22:15:26.691060Z",
     "shell.execute_reply": "2022-07-10T22:15:26.690062Z",
     "shell.execute_reply.started": "2022-07-10T22:15:21.078516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20378/587712301.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdf['input_ids'].loc[i] = row['input_ids'][:max_length]\n",
      "/tmp/ipykernel_20378/587712301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdf['attention_mask'].loc[i] = row['attention_mask'][:max_length]\n",
      "/tmp/ipykernel_20378/587712301.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdf['labels'].loc[i] = row['labels'][:max_length]\n"
     ]
    }
   ],
   "source": [
    "for i, row in pdf.iterrows():\n",
    "    pdf['input_ids'].loc[i] = row['input_ids'][:max_length]\n",
    "    pdf['attention_mask'].loc[i] = row['attention_mask'][:max_length]\n",
    "    pdf['labels'].loc[i] = row['labels'][:max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:27.415545Z",
     "iopub.status.busy": "2022-07-10T22:15:27.414680Z",
     "iopub.status.idle": "2022-07-10T22:15:30.609695Z",
     "shell.execute_reply": "2022-07-10T22:15:30.608683Z",
     "shell.execute_reply.started": "2022-07-10T22:15:27.415507Z"
    },
    "papermill": {
     "duration": 3.359641,
     "end_time": "2021-12-23T23:16:52.096508",
     "exception": false,
     "start_time": "2021-12-23T23:16:48.736867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 74\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use HuggingFace datasets\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "ds_train = Dataset.from_pandas(pdf[pdf.fold != 0][['input_ids', 'attention_mask', 'labels']].reset_index(drop=True))\n",
    "ds_valid = Dataset.from_pandas(pdf[pdf.fold == 0][['input_ids', 'attention_mask', 'labels']].reset_index(drop=True))\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:30.612473Z",
     "iopub.status.busy": "2022-07-10T22:15:30.611762Z",
     "iopub.status.idle": "2022-07-10T22:15:35.347329Z",
     "shell.execute_reply": "2022-07-10T22:15:35.346328Z",
     "shell.execute_reply.started": "2022-07-10T22:15:30.612432Z"
    },
    "papermill": {
     "duration": 19.979252,
     "end_time": "2021-12-23T23:17:12.107453",
     "exception": false,
     "start_time": "2021-12-23T23:16:52.128201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=max_length, padding='max_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037173,
     "end_time": "2021-12-23T23:21:07.087901",
     "exception": false,
     "start_time": "2021-12-23T23:21:07.050728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:35.349115Z",
     "iopub.status.busy": "2022-07-10T22:15:35.348757Z",
     "iopub.status.idle": "2022-07-10T22:15:38.978276Z",
     "shell.execute_reply": "2022-07-10T22:15:38.977329Z",
     "shell.execute_reply.started": "2022-07-10T22:15:35.349078Z"
    },
    "papermill": {
     "duration": 56.699428,
     "end_time": "2021-12-23T23:22:03.824514",
     "exception": false,
     "start_time": "2021-12-23T23:21:07.125086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# we will use auto model for token classification\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:38.981856Z",
     "iopub.status.busy": "2022-07-10T22:15:38.981063Z",
     "iopub.status.idle": "2022-07-10T22:15:39.021074Z",
     "shell.execute_reply": "2022-07-10T22:15:39.020143Z",
     "shell.execute_reply.started": "2022-07-10T22:15:38.981810Z"
    },
    "papermill": {
     "duration": 1.427191,
     "end_time": "2021-12-23T23:22:05.286874",
     "exception": false,
     "start_time": "2021-12-23T23:22:03.859683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BS,\n",
    "    per_device_eval_batch_size=BS,\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    weight_decay=WD,\n",
    "    report_to='wandb', \n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    warmup_ratio=WARMUP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:39.023007Z",
     "iopub.status.busy": "2022-07-10T22:15:39.022587Z",
     "iopub.status.idle": "2022-07-10T22:15:39.029693Z",
     "shell.execute_reply": "2022-07-10T22:15:39.026917Z",
     "shell.execute_reply.started": "2022-07-10T22:15:39.022971Z"
    },
    "papermill": {
     "duration": 2.251221,
     "end_time": "2021-12-23T23:22:07.573273",
     "exception": false,
     "start_time": "2021-12-23T23:22:05.322052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, padding='max_length', return_tensors='pt', max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:39.031776Z",
     "iopub.status.busy": "2022-07-10T22:15:39.031212Z",
     "iopub.status.idle": "2022-07-10T22:15:39.675760Z",
     "shell.execute_reply": "2022-07-10T22:15:39.674621Z",
     "shell.execute_reply.started": "2022-07-10T22:15:39.031737Z"
    },
    "papermill": {
     "duration": 3.152529,
     "end_time": "2021-12-23T23:22:10.763315",
     "exception": false,
     "start_time": "2021-12-23T23:22:07.610786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is not the competition metric, but for now this will be better than nothing...\n",
    "\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:39.677837Z",
     "iopub.status.busy": "2022-07-10T22:15:39.677260Z",
     "iopub.status.idle": "2022-07-10T22:15:39.687382Z",
     "shell.execute_reply": "2022-07-10T22:15:39.686026Z",
     "shell.execute_reply.started": "2022-07-10T22:15:39.677799Z"
    },
    "papermill": {
     "duration": 2.277937,
     "end_time": "2021-12-23T23:22:13.105373",
     "exception": false,
     "start_time": "2021-12-23T23:22:10.827436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [i2l[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [i2l[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:39.689273Z",
     "iopub.status.busy": "2022-07-10T22:15:39.688897Z",
     "iopub.status.idle": "2022-07-10T22:15:41.626393Z",
     "shell.execute_reply": "2022-07-10T22:15:41.625404Z",
     "shell.execute_reply.started": "2022-07-10T22:15:39.689236Z"
    },
    "papermill": {
     "duration": 6.123749,
     "end_time": "2021-12-23T23:22:19.267169",
     "exception": false,
     "start_time": "2021-12-23T23:22:13.143420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:41.629944Z",
     "iopub.status.busy": "2022-07-10T22:15:41.629552Z",
     "iopub.status.idle": "2022-07-10T22:15:41.635722Z",
     "shell.execute_reply": "2022-07-10T22:15:41.634713Z",
     "shell.execute_reply.started": "2022-07-10T22:15:41.629906Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T22:15:41.637780Z",
     "iopub.status.busy": "2022-07-10T22:15:41.637098Z"
    },
    "papermill": {
     "duration": 17616.128209,
     "end_time": "2021-12-24T04:15:55.431150",
     "exception": false,
     "start_time": "2021-12-23T23:22:19.302941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdarek\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/darek/projects/fbck/notebooks/wandb/run-20220713_070220-1zavmdwm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/darek/huggingface/runs/1zavmdwm\" target=\"_blank\">longformer-base-4096-finetuned-ner</a></strong> to <a href=\"https://wandb.ai/darek/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:59, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.302700</td>\n",
       "      <td>1.132093</td>\n",
       "      <td>0.177898</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>0.040981</td>\n",
       "      <td>0.392452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.238900</td>\n",
       "      <td>1.330562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.192400</td>\n",
       "      <td>1.191774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.139600</td>\n",
       "      <td>1.143918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>1.131410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Effective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Adequate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Ineffective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Effective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Adequate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Ineffective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Effective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Adequate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Ineffective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Effective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Adequate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Ineffective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Effective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Adequate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Ineffective seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/darek/miniconda3/envs/ml/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁████</td></tr><tr><td>eval/f1</td><td>█▁▁▁▁</td></tr><tr><td>eval/loss</td><td>▁█▃▁▁</td></tr><tr><td>eval/precision</td><td>█▁▁▁▁</td></tr><tr><td>eval/recall</td><td>█▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▂▇▂█</td></tr><tr><td>eval/samples_per_second</td><td>█▇▂▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▂▇▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.39302</td></tr><tr><td>eval/f1</td><td>0.0</td></tr><tr><td>eval/loss</td><td>1.13141</td></tr><tr><td>eval/precision</td><td>0.0</td></tr><tr><td>eval/recall</td><td>0.0</td></tr><tr><td>eval/runtime</td><td>1.0786</td></tr><tr><td>eval/samples_per_second</td><td>24.106</td></tr><tr><td>eval/steps_per_second</td><td>6.49</td></tr><tr><td>train/epoch</td><td>4.84</td></tr><tr><td>train/global_step</td><td>10</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.964</td></tr><tr><td>train/total_flos</td><td>235161986088960.0</td></tr><tr><td>train/train_loss</td><td>1.16753</td></tr><tr><td>train/train_runtime</td><td>66.9983</td></tr><tr><td>train/train_samples_per_second</td><td>5.523</td></tr><tr><td>train/train_steps_per_second</td><td>0.149</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-base-4096-finetuned-ner</strong>: <a href=\"https://wandb.ai/darek/huggingface/runs/1zavmdwm\" target=\"_blank\">https://wandb.ai/darek/huggingface/runs/1zavmdwm</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220713_070220-1zavmdwm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 1.213739,
     "end_time": "2021-12-24T04:15:56.696172",
     "exception": false,
     "start_time": "2021-12-24T04:15:55.482433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054075,
     "end_time": "2021-12-24T04:15:56.805502",
     "exception": false,
     "start_time": "2021-12-24T04:15:56.751427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.066312,
     "end_time": "2021-12-24T04:15:56.924543",
     "exception": false,
     "start_time": "2021-12-24T04:15:56.858231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_for_validation(examples):\n",
    "\n",
    "    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n",
    "\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    \n",
    "    o[\"labels\"] = []\n",
    "\n",
    "    for i in range(len(offset_mapping)):\n",
    "                   \n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][i], examples['ends'][i], examples['classlist'][i])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start: \n",
    "                    labels[j] = l2i[f'B-{label}']    \n",
    "                if token_start > label_start and token_end <= label_end: \n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "\n",
    "        labels = fix_beginnings(labels)\n",
    "                   \n",
    "        o[\"labels\"].append(labels)\n",
    "        \n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 121.539983,
     "end_time": "2021-12-24T04:17:58.516649",
     "exception": false,
     "start_time": "2021-12-24T04:15:56.976666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_val = datasets.map(tokenize_for_validation, batched=True)\n",
    "tokenized_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.629151,
     "end_time": "2021-12-24T04:18:03.199393",
     "exception": false,
     "start_time": "2021-12-24T04:17:58.570242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ground truth for validation\n",
    "\n",
    "l = []\n",
    "for example in tokenized_val['test']:\n",
    "    for c, p in list(zip(example['classlist'], example['predictionstrings'])):\n",
    "        l.append({\n",
    "            'id': example['id'],\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': p,\n",
    "        })\n",
    "    \n",
    "gt_df = pd.DataFrame(l)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.242082,
     "end_time": "2021-12-24T04:18:07.495695",
     "exception": false,
     "start_time": "2021-12-24T04:18:03.253613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualization with displacy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from pylab import cm, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.066481,
     "end_time": "2021-12-24T04:18:07.617965",
     "exception": false,
     "start_time": "2021-12-24T04:18:07.551484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path('../input/feedback-prize-2021/train')\n",
    "\n",
    "colors = {\n",
    "            'Lead': '#8000ff',\n",
    "            'Position': '#2b7ff6',\n",
    "            'Evidence': '#2adddd',\n",
    "            'Claim': '#80ffb4',\n",
    "            'Concluding Statement': 'd4dd80',\n",
    "            'Counterclaim': '#ff8042',\n",
    "            'Rebuttal': '#ff0000',\n",
    "            'Other': '#007f00',\n",
    "         }\n",
    "\n",
    "def visualize(df, text):\n",
    "    ents = []\n",
    "    example = df['id'].loc[0]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ents.append({\n",
    "                        'start': int(row['discourse_start']), \n",
    "                         'end': int(row['discourse_end']), \n",
    "                         'label': row['discourse_type']\n",
    "                    })\n",
    "\n",
    "    doc2 = {\n",
    "        \"text\": text,\n",
    "        \"ents\": ents,\n",
    "        \"title\": example\n",
    "    }\n",
    "\n",
    "    options = {\"ents\": train.discourse_type.unique().tolist() + ['Other'], \"colors\": colors}\n",
    "    displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 139.546569,
     "end_time": "2021-12-24T04:20:27.220350",
     "exception": false,
     "start_time": "2021-12-24T04:18:07.673781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_val['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.357266,
     "end_time": "2021-12-24T04:20:27.729601",
     "exception": false,
     "start_time": "2021-12-24T04:20:27.372335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions, axis=-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.223622,
     "end_time": "2021-12-24T04:20:28.217041",
     "exception": false,
     "start_time": "2021-12-24T04:20:27.993419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code that will convert our predictions into prediction strings, and visualize it at the same time\n",
    "# this most likely requires some refactoring\n",
    "\n",
    "def get_class(c):\n",
    "    if c == 14: return 'Other'\n",
    "    else: return i2l[c][2:]\n",
    "\n",
    "def pred2span(pred, example, viz=False, test=False):\n",
    "    example_id = example['id']\n",
    "    n_tokens = len(example['input_ids'])\n",
    "    classes = []\n",
    "    all_span = []\n",
    "    for i, c in enumerate(pred.tolist()):\n",
    "        if i == n_tokens-1:\n",
    "            break\n",
    "        if i == 0:\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n",
    "            cur_span[1] = example['offset_mapping'][i][1]\n",
    "        else:\n",
    "            all_span.append(cur_span)\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "    all_span.append(cur_span)\n",
    "    \n",
    "    if test: text = get_test_text(example_id)\n",
    "    else: text = get_raw_text(example_id)\n",
    "    \n",
    "    # abra ka dabra se soli fanta ko pelo\n",
    "    \n",
    "    # map token ids to word (whitespace) token ids\n",
    "    predstrings = []\n",
    "    for span in all_span:\n",
    "        span_start = span[0]\n",
    "        span_end = span[1]\n",
    "        before = text[:span_start]\n",
    "        token_start = len(before.split())\n",
    "        if len(before) == 0: token_start = 0\n",
    "        elif before[-1] != ' ': token_start -= 1\n",
    "        num_tkns = len(text[span_start:span_end+1].split())\n",
    "        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n",
    "        predstring = ' '.join(tkns)\n",
    "        predstrings.append(predstring)\n",
    "                    \n",
    "    rows = []\n",
    "    for c, span, predstring in zip(classes, all_span, predstrings):\n",
    "        e = {\n",
    "            'id': example_id,\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': predstring,\n",
    "            'discourse_start': span[0],\n",
    "            'discourse_end': span[1],\n",
    "            'discourse': text[span[0]:span[1]+1]\n",
    "        }\n",
    "        rows.append(e)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n",
    "    \n",
    "    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n",
    "    df = df[df.length > min_tokens].reset_index(drop=True)\n",
    "    if viz: visualize(df, text)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.196483,
     "end_time": "2021-12-24T04:20:28.565011",
     "exception": false,
     "start_time": "2021-12-24T04:20:28.368528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred2span(preds[0], tokenized_val['test'][0], viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.19199,
     "end_time": "2021-12-24T04:20:28.911524",
     "exception": false,
     "start_time": "2021-12-24T04:20:28.719534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred2span(preds[1], tokenized_val['test'][1], viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 14.475641,
     "end_time": "2021-12-24T04:20:43.539768",
     "exception": false,
     "start_time": "2021-12-24T04:20:29.064127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(len(tokenized_val['test'])):\n",
    "    dfs.append(pred2span(preds[i], tokenized_val['test'][i]))\n",
    "\n",
    "pred_df = pd.concat(dfs, axis=0)\n",
    "pred_df['class'] = pred_df['discourse_type']\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.176864,
     "end_time": "2021-12-24T04:20:43.876324",
     "exception": false,
     "start_time": "2021-12-24T04:20:43.699460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/robikscube/student-writing-competition-twitch#Competition-Metric-Code\n",
    "\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp_micro(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = (\n",
    "        gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    pred_df[\"pred_id\"] = pred_df.index\n",
    "    gt_df[\"gt_id\"] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=[\"id\", \"class\"],\n",
    "        right_on=[\"id\", \"discourse_type\"],\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    )\n",
    "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "    tp_pred_ids = (\n",
    "        joined.query(\"potential_TP\")\n",
    "        .sort_values(\"max_overlap\", ascending=False)\n",
    "        .groupby([\"id\", \"predictionstring_gt\"])\n",
    "        .first()[\"pred_id\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    # calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n",
    "    return my_f1_score\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n",
    "        pred_subset = (\n",
    "            pred_df.loc[pred_df[\"class\"] == discourse_type]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "        )\n",
    "        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.157584,
     "end_time": "2021-12-24T04:20:44.191164",
     "exception": false,
     "start_time": "2021-12-24T04:20:44.033580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.307675,
     "end_time": "2021-12-24T04:20:47.654956",
     "exception": false,
     "start_time": "2021-12-24T04:20:44.347281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_feedback_comp(pred_df, gt_df, return_class_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.155092,
     "end_time": "2021-12-24T04:20:47.969846",
     "exception": false,
     "start_time": "2021-12-24T04:20:47.814754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## End\n",
    "\n",
    "I'll appreciate every upvote or comment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
