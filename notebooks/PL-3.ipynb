{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c4a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1deb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'PL3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9a244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import spacy\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import pickle\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e63f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020a0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=1024, stage='train', rand_prob=0.1, lowup_proba=0.0, swap_proba=0.0):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "        self.stage = stage\n",
    "        self.rand_prob = rand_prob\n",
    "        self.lowup_proba = lowup_proba\n",
    "        self.swap_proba = swap_proba\n",
    "\n",
    "        self.essay_id = df['essay_id'].values\n",
    "        self.input_ids = df['input_ids'].values\n",
    "        self.attention_mask = df['attention_mask'].values\n",
    "        self.offset_mapping = df['offset_mapping'].values\n",
    "        self.token_class_labels = df['token_class_labels'].values\n",
    "        self.token_scores_labels = df['token_scores_labels'].values\n",
    "        self.token_examples_mapping = df['token_examples_mapping'].values\n",
    "        self.examples_scores = df['examples_scores'].values\n",
    "        self.examples_classes = df['examples_classes'].values    \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        essay_id = self.essay_id[idx]\n",
    "        offset_mapping = self.offset_mapping[idx]\n",
    "\n",
    "        token_examples_mapping = self.token_examples_mapping[idx]\n",
    "        examples_scores = self.examples_scores[idx]\n",
    "        examples_classes = self.examples_classes[idx]\n",
    "\n",
    "        token_examples_mapping = torch.tensor(token_examples_mapping, dtype=torch.long)\n",
    "        examples_scores = torch.tensor(examples_scores + [-1] * (40 - len(examples_scores)), dtype=torch.long)\n",
    "        examples_classes = torch.tensor(examples_classes + [-1] * (40 - len(examples_classes)), dtype=torch.long)\n",
    "        \n",
    "        input_ids = self.input_ids[idx]\n",
    "        attention_mask = self.attention_mask[idx]\n",
    "        token_class_labels = self.token_class_labels[idx]\n",
    "        token_scores_labels = self.token_scores_labels[idx]\n",
    "\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
    "        token_class_labels = torch.tensor(token_class_labels, dtype=torch.long)\n",
    "        token_scores_labels = torch.tensor(token_scores_labels, dtype=torch.long)\n",
    "\n",
    "        if self.stage == 'train':\n",
    "            ix = torch.rand(size=(self.max_len,)) < self.rand_prob\n",
    "            input_ids[ix] = self.mask_token\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_class_labels\": token_class_labels,\n",
    "            \"token_scores_labels\": token_scores_labels,\n",
    "            \"token_examples_mapping\": token_examples_mapping,\n",
    "            \"examples_scores\": examples_scores,\n",
    "            \"examples_classes\": examples_classes\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9aabbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(pl.LightningModule):\n",
    "    def __init__(self, lr, model_checkpoint, num_classes):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.name = model_checkpoint\n",
    "        self.pad_idx = 1 if \"roberta\" in self.name else 0\n",
    "        config = AutoConfig.from_pretrained(model_checkpoint, output_hidden_states=True)\n",
    "        self.transformer = AutoModel.from_pretrained(model_checkpoint, config=config)\n",
    "        self.nb_features = config.hidden_size\n",
    "        self.logits = nn.Linear(self.nb_features, num_classes)        \n",
    "        transformers.logging.set_verbosity_error()\n",
    "    \n",
    "    def forward(self, example):\n",
    "        input_ids, attention_mask = \\\n",
    "            example[\"input_ids\"], example[\"attention_mask\"]\n",
    "        hidden_states = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )[-1]\n",
    "        features = hidden_states[-1]\n",
    "        logits = self.logits(features)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': 1e-5, 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': 1e-5, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_parameters, lr=self.lr)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=100,\n",
    "            num_training_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]\n",
    "                \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        input_ids, attention_mask, token_scores_labels = \\\n",
    "            train_batch[\"input_ids\"], train_batch[\"attention_mask\"], train_batch[\"token_scores_labels\"]\n",
    "        hidden_states = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )[-1]\n",
    "        features = hidden_states[-1]\n",
    "        logits = self.logits(features)\n",
    "        loss = F.cross_entropy(logits.view(-1, self.num_classes), token_scores_labels.view(-1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        input_ids, attention_mask, token_scores_labels, token_examples_mapping, examples_scores, examples_classes = \\\n",
    "            val_batch[\"input_ids\"], val_batch[\"attention_mask\"], val_batch[\"token_scores_labels\"], \\\n",
    "            val_batch['token_examples_mapping'], val_batch['examples_scores'], val_batch['examples_classes']\n",
    "        hidden_states = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )[-1]\n",
    "        features = hidden_states[-1]\n",
    "        logits = self.logits(features)\n",
    "        y_pred = F.log_softmax(logits, dim=-1)                                                \n",
    "        loss = F.cross_entropy(logits.view(-1, self.num_classes), token_scores_labels.view(-1))\n",
    "        self.log('val_loss', loss)\n",
    "        return {\"preds\": y_pred,\n",
    "                \"logits\": logits,\n",
    "                \"val_losses\": loss,\n",
    "                \"token_examples_mapping\": token_examples_mapping,\n",
    "                \"examples_scores\": examples_scores,\n",
    "                \"examples_classes\": examples_classes}   \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "        bs, ml, nc1 = validation_step_outputs[0][\"preds\"].shape\n",
    "        ml2 = validation_step_outputs[0][\"examples_scores\"].shape[-1]\n",
    "        all_preds = torch.cat([x[\"preds\"] for x in validation_step_outputs], dim=0).view(-1, ml, nc1)\n",
    "        all_mappings = torch.cat([x[\"token_examples_mapping\"] for x in validation_step_outputs], dim=0).view(-1, ml)\n",
    "        all_scores = torch.cat([x[\"examples_scores\"] for x in validation_step_outputs], dim=0).view(-1, ml2)\n",
    "        \n",
    "        num_texts = all_scores.shape[0]\n",
    "        \n",
    "        example_preds = []\n",
    "        example_targs = []\n",
    "        \n",
    "        for i in range(num_texts):\n",
    "            num_examples = all_mappings[i].max()\n",
    "            assert all_scores[i,num_examples] >= 0 # and all_scores[i,num_examples+1] < 0 # truncation breaks this\n",
    "            for j in range(num_examples + 1):\n",
    "                indices = all_mappings[i] == j\n",
    "                preds = all_preds[i][indices].mean(dim=0)\n",
    "                example_preds.append(preds)\n",
    "                example_targs.append(all_scores[i,j].view(1))\n",
    "                \n",
    "        example_preds = torch.cat(example_preds, dim=0).view(-1, nc1)\n",
    "        example_targs = torch.cat(example_targs, dim=0)\n",
    "        \n",
    "        example_loss = F.nll_loss(example_preds, example_targs)\n",
    "        self.log('example_loss', example_loss)\n",
    "        print(example_loss)\n",
    "        \n",
    "    def predict_step(self, val_batch, batch_idx):\n",
    "        input_ids, attention_mask, token_scores_labels, token_examples_mapping, examples_scores, examples_classes = \\\n",
    "            val_batch[\"input_ids\"], val_batch[\"attention_mask\"], val_batch[\"token_scores_labels\"], \\\n",
    "            val_batch['token_examples_mapping'], val_batch['examples_scores'], val_batch['examples_classes']\n",
    "        hidden_states = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )[-1]\n",
    "        features = hidden_states[-1]\n",
    "        logits = self.logits(features)\n",
    "        y_pred = F.softmax(logits, dim=-1)  \n",
    "        \n",
    "        bs, ml, nc1 = logits.shape\n",
    "        ml2 = 40\n",
    "#         all_preds = torch.cat([x[\"preds\"] for x in validation_step_outputs], dim=0).view(-1, ml, nc1)\n",
    "#         all_mappings = torch.cat([x[\"token_examples_mapping\"] for x in validation_step_outputs], dim=0).view(-1, ml)\n",
    "#         all_scores = torch.cat([x[\"examples_scores\"] for x in validation_step_outputs], dim=0).view(-1, ml2)\n",
    "        \n",
    "#         num_texts = all_scores.shape[0]\n",
    "        \n",
    "        batch_preds = []\n",
    "        batch_targs = []\n",
    "        \n",
    "        for i in range(bs):\n",
    "            example_preds = []\n",
    "            example_targs = []\n",
    "            num_examples = token_examples_mapping[i].max()\n",
    "            assert examples_scores[i,num_examples] >= 0 # and examples_scores[i,num_examples+1] < 0 # truncation breaks this\n",
    "            for j in range(num_examples + 1):\n",
    "                indices = token_examples_mapping[i] == j\n",
    "                preds = logits[i][indices].mean(dim=0)\n",
    "                example_preds.append(preds)\n",
    "                example_targs.append(examples_scores[i,j].view(1))\n",
    "                \n",
    "            example_preds = torch.cat(example_preds, dim=0).view(-1, nc1)\n",
    "            example_targs = torch.cat(example_targs, dim=0)\n",
    "            batch_preds.append(example_preds)\n",
    "            batch_targs.append(example_targs)\n",
    "        \n",
    "#         batch_preds = torch.cat(batch_preds, dim=0).view(-1, nc1)\n",
    "#         batch_targs = torch.cat(batch_targs, dim=0)\n",
    "        \n",
    "        return batch_preds, batch_targs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14066891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('processed.pickle', 'rb') as handle:\n",
    "    pdf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be2399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['debug'] if DEBUG else ['train']\n",
    "if DEBUG: pdf = pdf.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6c8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pdf[pdf.fold != 0].reset_index(drop=True)\n",
    "df_valid = pdf[pdf.fold == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afc879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdarek\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/darek/projects/fbck/notebooks/wandb/run-20220714_170503-j3tes7ea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/darek/fbck/runs/j3tes7ea\" target=\"_blank\">fallen-haze-37</a></strong> to <a href=\"https://wandb.ai/darek/fbck\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = 'fbck'\n",
    "run = wandb.init(project=project, tags=tags)\n",
    "run.log_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921da3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "OUTPUT_DIR = '../output'\n",
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb774a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'allenai/longformer-large-4096'\n",
    "max_length = 1024\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=max_length, padding='max_length')\n",
    "bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d96328",
   "metadata": {},
   "outputs": [],
   "source": [
    "randmask_proba = 0.15\n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    df_train,\n",
    "    tokenizer,\n",
    "    max_len=max_length,\n",
    "    stage='train',\n",
    "    rand_prob=randmask_proba\n",
    ")\n",
    "\n",
    "valid_dataset = MyDataset(\n",
    "    df_valid,\n",
    "    tokenizer,\n",
    "    max_len=max_length,\n",
    "    stage='train',\n",
    "    rand_prob=randmask_proba\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b898f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=bs,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=bs,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9932e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "epochs = 2 if DEBUG else 5\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99520b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-large-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MyModule(lr=lr,\n",
    "                 model_checkpoint=model_checkpoint, \n",
    "                 num_classes=num_classes\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e3d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c746c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=2,\n",
    "    monitor=\"example_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=f\"../output/{EXP}/\",\n",
    "    filename=\"feedback-{epoch:02d}-{example_loss:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93d9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=epochs,\n",
    "                     log_every_n_steps=100, logger=wandb_logger,\n",
    "                     default_root_dir=f\"../output/{EXP}\",\n",
    "                     callbacks=[checkpoint_callback],\n",
    "                     accumulate_grad_batches=8\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cefb6a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type            | Params\n",
      "------------------------------------------------\n",
      "0 | transformer | LongformerModel | 434 M \n",
      "1 | logits      | Linear          | 3.1 K \n",
      "------------------------------------------------\n",
      "434 M     Trainable params\n",
      "0         Non-trainable params\n",
      "434 M     Total params\n",
      "1,738.416 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9279, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb2c1216b1e4b9cb5d2701ca8a0d4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7159, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6976, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6985, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7224, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7133, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fee0504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆█████</td></tr><tr><td>example_loss</td><td>▆▁▁█▅</td></tr><tr><td>train_loss</td><td>▅▄▅▃▂▄▃▄▅▁▆█▃▄▃▁▆▇▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>example_loss</td><td>0.71334</td></tr><tr><td>train_loss</td><td>0.25054</td></tr><tr><td>trainer/global_step</td><td>2094</td></tr><tr><td>val_loss</td><td>0.65398</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-haze-37</strong>: <a href=\"https://wandb.ai/darek/fbck/runs/j3tes7ea\" target=\"_blank\">https://wandb.ai/darek/fbck/runs/j3tes7ea</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220714_170503-j3tes7ea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea945506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'feedback-epoch=01-example_loss=0.70.ckpt'\r\n",
      "'feedback-epoch=02-example_loss=0.70.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls ../output/PL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cfedb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fbcd8dd2b44ca2b192217b87e41fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# or call with pretrained model\n",
    "PATH = '../output/PL3/feedback-epoch=02-example_loss=0.70.ckpt'\n",
    "model = MyModule.load_from_checkpoint(PATH, lr=lr,\n",
    "                 model_checkpoint=model_checkpoint, \n",
    "                 num_classes=num_classes)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\")\n",
    "# trainer.validate(model, dataloaders=val_loader)\n",
    "predictions = trainer.predict(model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "236a294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat([p for b in predictions for p in b[0]])\n",
    "targs = torch.cat([p for b in predictions for p in b[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d658c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7094, 3]), torch.Size([7094]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e94b3111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6919)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54729a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6934)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds.argmax(dim=-1) == targs).sum()/preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b21c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why aren't these preds deterministic????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f169c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
